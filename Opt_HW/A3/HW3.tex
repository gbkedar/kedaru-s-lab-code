\documentclass[12pt]{report}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\providecommand{\norm}[1]{\lVert#1\rVert}

\begin{document}

\begin{center}
	\large{Optimization - MATH 6366}\\
	\hfill \hfill \large{Homework \#3} \hfill \large{Kedar Grama}\\
\end{center}

\section*{Problem 2:}
(a) Let $C$ be the unit simplex in $\mathbb{R}^2$, a closed convex set generated by $\{ 0,
e^{(1)}, e^{(2)} \}$ $e^{(1)}=(1,0)$, $e^{(2)}=(0,1)$. Then tangent cone
$T_x(c) = \mathbb{R}^2$ if $x$ is an interior point of $C$ and the normal cone is
$N_x(C)=0$.\\
When $x=(0,0)$ then the tangent cone is $T_{(0,0)}(c) = \{ (y_1,y_2):y_1\geq 0, y_2\geq 0 \}$
and the normal cone is $N_{(0,0)}(c) = -\mathbb{R}^2_+ = \{(y_1,y_2):y_1\leq 0, y_2\leq 0 \}$.
\\ Find the tangent and normal cones to $C$ at the vertices $e^{(1)}$, $e^{(2)}$ of $C$.\\ 
$Solution$: Using the definition of the tangent and normal cones given in class:\\
At $e^{(1)}=(1,0)$\\
$T_{(1,0)}(c) = \{ y_2 \leq 0 , y_1+y_2-1 \geq 0 \}$ and \\
$N_{(1,0)}(c) = \{ y_1 \geq 1 , y_1-y_2+1 \leq 0 \}$ \\
At $e^{(2)}=(0,1)$\\
$T_{(0,1)}(c) = \{ y_1 \leq 0 , y_1+y_2-1 \geq 0 \}$ and \\
$N_{(0,1)}(c) = \{ y_2 \geq 1 , -y_1+y_2-1 \geq 0 \}$\\
\\
(b) Assume that a function $f : \mathbb{R}^2 \rightarrow \mathbb{R}$ is $C^1$ and is minimized
on the unit triangle $\Delta_2 := co\{ 0, e^{(1)} , e^{(2)} \} \subset \mathbb{R}^2$ at the
origin. What are the optimality conditions that hold in this case? \\ \\
$Solution$: We can rewrite the given problem and the constraints in the standard form as:
\begin{equation*}
\text{Minimize $f(x)$ subject to}\left\{
  \begin{array}{l l}
    g_1(x): & \quad x_1+x_2-1 \leq 0\\
    g_2(x): & \quad -x_1 \leq 0 \\
    g_3(x): & \quad -x_2 \leq 0 \\
  \end{array} \right.
\end{equation*}
If $x^*$ is the optimizer, the KKT conditions that need to hold are:
\begin{align*}
\nabla f(x^*) + \sum_{i=1}^3 \mu_i \nabla g_i(x^*) &= 0 \\
g_i(x^*) & \leq 0 , i=1,2,3\\
\mu_i & \geq 0 , i=1,2,3\\
\mu_i g_i(x^*) &= 0, i=1,2,3
\end{align*}

\section*{Problem 3:}
Suppose $A$ is an $M \times N$ real matrix and $b\in\mathbb{R}^N $. \\
(a) Find the linear equation that must hold at the minimizers of
$f : \mathbb{R}^N \rightarrow \mathbb{R}$ defined by $$ f (x) := \| Ax-b \|_2^2 $$
Since this is an unconstrained optimization problem we need the first order necessary
condition(FONC) and the second order necessary condition(SONC) to hold at the minimizer $x^*$. The
SONC is
\begin{align*}
\nabla^2 f(x^*) & \quad \text{positive semidefinite} \\
2A^TA & \quad \text{positive semidefinite or} \\
y^T(A^TA)y & \geq 0 \forall y \in \mathbb{R}^N
\end{align*}
The FONC is:
\begin{align*}
\nabla f(x^*) &= 0 \quad \text{or} \\
2A^T(Ax^*-b) &= 0 \\
A^T(Ax^*-b) &= 0
\end{align*}
So the above linear equation must hold.\\
(b) If $x$ is a solution of the linear equation you obtained in part (a), how would you decide
whether or not $x$ is actually a solution of $Ax = b$?\\
$Solution$: If the rank($A^T$)=$M$ then the vector $y$ that solves $A^Ty=0$ can only be the null
vector $y=0$. So, if the rank($A$)=$N$ then the solution of $Ax=b$ will be correct but if
rank($A$)$<N$ then we need to compare the result and it is likely that the space spanned by $b$
that is in the null space of $A$ will not be accounted for in the solution.

\pagebreak

\section*{Problem 1:}
Prove: If $\{g_1,g_2,\dots,g_M\}$ are closed convex functions on $\mathbb{R}^N$ and \\
$C:=\{x\in\mathbb{R}^N:g_j(x)\leq c_j$ for $1\leq j \leq M \}$ then $C$ is closed and
convex.\\
$Proof$: We'll prove convexity and closedness separately.\\
Closed set: Let
\begin{align*}
C^c=\mathbb{R}^N \backslash C &= \cup_{j=1}^M \{ x \in \mathbb{R}^N:g_j(x) > c_j \}
\end{align*}
For some $\epsilon>0$ $\exists$ $\delta_j >0$ for every $\hat{x}\in C^c$ such that
$\forall x \in B(\hat{x},\delta_j)$, a ball, and \\
$g_j(\hat{x})-\epsilon<g_j(x)<g_j(\hat{x})+\epsilon$. Let $\epsilon = g_j(\hat{x})-c_j>0$ 
then $\exists$ $\delta_j'>0$ such that
$\forall$ $x\in B(\hat{x},\delta_j')$, $g_j(x)>g_j(\hat{x})-\epsilon$ or $g_j(x)>c_j$. Hence $C^c$
is and open set which implies $C$ is closed.

Convexity: Since we have that $g_j(x)$ is convex by the definition of convexity we have for
$\lambda \in [0,1] $ and some $x_1,x_2\in C$
\begin{align*}
g_j(\lambda x_1+ (1-\lambda)x_2) &\leq \lambda g_j(x_1) + (1-\lambda) g_j(x_2) \\
& \leq \lambda c_j + (1-\lambda) c_j = c_j 
\end{align*}
Since $\lambda x_1+ (1-\lambda)x_2 \in C, \lambda \in [0,1] $, $C$ is convex.



\end{document}

