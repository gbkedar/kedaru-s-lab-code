\documentclass[12pt]{report}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\providecommand{\norm}[1]{\lVert#1\rVert}

\begin{document}

\begin{center}
	\large{Optimization - MATH 6366}\\
	\hfill \hfill \large{Homework \#7} \hfill \large{Kedar Grama}\\
\end{center}
Please notify me on my grade
\section*{Problem 1:}
(i) Using the given conditions we have:
\begin{align*}
\sum_{j=1}^{N} \left( c_j-\mu \right)^2x_j &= \sigma^2 \\
\sum_{j=1}^{N} \left( c_j^2x_j - 2c_jx_j \mu + \mu^2x_j \right) &= \sigma^2 \\
\sum_{j=1}^{N}c_j^2x_j - 2\left( \sum_{j=1}c_jx_j \right) \mu + \left( \sum_{j=1}^{N}x_j \right) \mu^2 &= \sigma^2 \\
\sum_{j=1}^{N}c_j^2x_j - 2\mu.\mu - 1.\mu^2 &= \sigma^2 \\
\sum_{j=1}^{N}c_j^2x_j &= \sigma^2+\mu^2
\end{align*}
As $0<c_1 \leq c_2 \dots \leq c_N $, $c_1 \leq \sigma^2+\mu^2 \leq c_N$ will generate a non-empty set and let's denote
this set as $\mathfrak{C}$

Take two points $x_1,x_2 \in \mathfrak{C}$ we need every point in $\lambda x_1 + (1-\lambda) x_2 \in \mathfrak{C}$, for 
$0\leq \lambda \leq 1 $
From the first given condition:
\begin{align*}
\sum_{j=1}^{N} \left( \lambda x_{1j} + (1- \lambda) x_{2j} \right) 
= \lambda(\sum x_{1j})+(1-\lambda)(\sum x_{2j}) = \lambda + (1-\lambda) = 1
\end{align*}
From the second given condition:
\begin{align*}
\sum_{j=1}^{N} c_j\left( \lambda x_{1j} + (1- \lambda) x_{2j} \right)
= \lambda(\sum c_j x_{1j} )+(1-\lambda)(\sum c_j x_{2j}) =  \lambda \mu + (1- \lambda) \mu = \mu
\end{align*}
From the third given condition:
\begin{align*}
\sum_{j=1}^{N} ( c_j-\mu )^2 ( \lambda x_{1j} + (1- \lambda) x_{2j} )
&=  \lambda \left( \sum( c_j-\mu )^2 x_{1j} \right) +(1- \lambda) \sum( c_j-\mu )^2x_{2j}\\
&= \lambda \sigma^2 + (1- \lambda) \sigma^2 = \sigma^2
\end{align*}
Hence the points are within $\mathfrak{C}$ $\implies$ the set is convex.\\
\\
(ii) The Lagrangian for this problem is: $L(x,\lambda)= S(x) + \sum_{i=1}^3 \lambda_i g_i(x) $ where $b_i(x)$ are the given
constraints $g_1 = \sum_{j=1}^Nx_j=1$, $g_2 = \sum_{j=1}^Nc_jx_j=\mu$ and $g_3 = (c_j-\mu)^2x_j=\sigma^2$\\
\\
(iii) The minimizers $\hat{x}$ of this problem satisfy:\\
$\nabla_x L(\hat{x},\lambda)=\nabla_x(S(\hat{x})+\sum g_i(\hat{x})\lambda_i)=0 $ and $g_i(\hat{x})=b_i$,
$\lambda_i\geq 0, i=1,2,3$ where 
\begin{align*}
A^T = \nabla_x g(\hat{x}) &= \left[\begin{array}{c c c c}
1 & 1 & \dots &1 \\
c_1 & c_2 & \dots & c_N \\
(c_1-\mu)^2 & (c_2-\mu)^2 & \dots & (c_N-\mu)^2
\end{array}\right]^T,
b= \left[ \begin{array}{c}
1 \\
\mu \\
\sigma^2
\end{array} \right] \\
\lambda &= \left[
\begin{array}{c}
\lambda_1 \\ \lambda_2 \\ \lambda_3 
\end{array}
\right] \text{ and }
\nabla_x S(\hat{x}) = \left[ \begin{array}{c}
\ln x_1 + 1 \\
\ln x_2 + 1 \\
\vdots \\
\ln x_N + 1 \\
\end{array} \right] 
\end{align*}
This can also be written as $\nabla_x L(\hat{x},\lambda) = \nabla_xS(\hat{x})+A^T\lambda=0 $\\
\\
(iv) It is easy to see as the problem is defined only the set $\mathbb{R}^N_+$ hence each component $x_j$ has to be positive
or $\hat{x}_j>0$ as ln 0 is undefined.

\section*{Problem 2:}
(i) The Lagrangian for this problem is: $L(x,\lambda) = f(x) + \sum_{i=1}^4 \lambda_i g_i(x)$, where:
$g_1(x) = -x_1 < 0 $,  $g_2(x) = -x_2 < 0 $,  $g_3(x) = -x_3 < 0 $ and \\ $g_4(x) = x_1 + x_2 + x_3-1 \leq 0$\\
\\
(ii) The extremality conditions that hold at $\hat{x}$ are:
\begin{align*}
\nabla_x L(\hat{x},\lambda)= 0 \text{ or }
\left[ \begin{array}{c}
1-\frac{1}{\hat{x}_1^2}-\lambda_1 \\
2-\frac{1}{\hat{x}_2^2}-\lambda_2 \\
3-\frac{1}{\hat{x}_3^2}-\lambda_3 
\end{array} \right] = 
\left[ \begin{array}{c}
0 \\ 0 \\ 0
\end{array} \right],
\end{align*}
$\lambda_i\geq 0$, $\lambda_i g_i(\hat{x}) = 0$ and $g_i(\hat{x}) \leq 0$ where $i=1,2,3,4$ \\
\\
(iii) The set $\mathfrak{C}=\{ x\in \mathbb{R}^3:g_i<0, i=1,2,3,4 \}$  which defines the domain of the problem is convex(easy to
see). So, we can write the dual problem as:
$$ \max_\mu \inf_{x\in \mathfrak{C} } \left( f(x) + \sum_{i=1}^4 \lambda_i g_i(x) \right) $$ s.t. $\lambda_i\geq 0$

\section*{Problem 3:}
(i) Writing $G(x)$ as $$G(x)=\sum_{j=1}^{N} c_j x_j +\sum_{j=1}^{N} x_j \ln x_j - \sum_{j=1}^{N} x_j \ln \left(\sum_{j=1}^{N} x_j 
\right) $$ then
\begin{align*}
\frac{\partial G(x)}{\partial x_1}&=
c_1 + \ln x_1+\frac{\sum_{j=1}^{N}x_j}{x_1}-\ln\left(\sum_{j=1}^{N}x_j\right)-\frac{\sum_{j=1}^{N}x_j}{x_1}\\
&= c_1 + \ln x_1-\ln\left(\sum_{j=1}^{N}x_j\right) = c_1 + \ln \left( \frac{x_1}{\sum_{j=1}^{N}x_j} \right)\\
\nabla G(x)&= \left[ \begin{array}{c}
c_1 + \ln \left(\frac{x_1}{\sum_{j=1}^{N}x_j}\right) \\
c_2 + \ln \left(\frac{x_2}{\sum_{j=1}^{N}x_j}\right) \\
\vdots\\
c_N + \ln \left(\frac{x_N}{\sum_{j=1}^{N}x_j}\right)
\end{array} \right]
\end{align*}

\begin{align*}
\frac{\partial G(x)}{\partial x_1 \partial x_1} = \frac{1}{x_1} - \frac{1}{\sum_{j=1}^{N}x_j}, 
\frac{\partial G(x)}{\partial x_1 \partial x_2} = -\frac{1}{\sum_{j=1}^{N}x_j} \\
D^2G(x) = \left[ \begin{array}{c c c c}
\frac{1}{x_1}-\frac{1}{\sum_{j=1}^{N}x_j} & \frac{-1}{\sum_{j=1}^{N}x_j} & \dots & \frac{-1}{\sum_{j=1}^{N}x_j} \\
\frac{-1}{\sum_{j=1}^{N}x_j} & \frac{1}{x_2}-\frac{1}{\sum_{j=1}^{N}x_j} & \dots & \frac{-1}{\sum_{j=1}^{N}x_j} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{-1}{\sum_{j=1}^{N}x_j} & \frac{-1}{\sum_{j=1}^{N}x_j} & \dots & \frac{1}{x_N}-\frac{1}{\sum_{j=1}^{N}x_j}
\end{array} \right]
\end{align*}
\\
(ii) Let $g_i(x) = -x_i \leq 0, i=1,2,\dots ,N$ and $h_k(x) = \langle a_k,x \rangle - b_k, k=1,2,\dots ,m$ where $a_k$ is the
$k^{th}$  row of $A$ and $b_k$ is the $k^{th}$ element of $b$. We can write the Lagrangian as:
$L(x,\lambda,\mu) = G(x) + \sum_{k=1}^N \lambda_k h_k(x) + \sum_{i=1}^N \mu_i g_i(x)$ and the equations that hold at Chemical
equilibrium $\hat{x}$ are:
\begin{align*}
\frac{\partial L}{\partial x }=0, \nabla G(\hat{x})+A^T\lambda-\mu = 0 \\
A\hat{x} = b
\mu_i \geq 0, i=1,2,\dots ,N \\
\mu_i \hat{x}_i = 0 , i=1,2,\dots ,N \\
\lambda_k \neq 0, k=1,2,\dots ,m \\
\hat{x}_k \geq 0, k=1,2,\dots ,m
\end{align*}

\end{document}

